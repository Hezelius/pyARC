{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running apriori with setting: confidence=0.5, support=0.0, minlen=2, maxlen=3, MAX_RULE_LEN=35\n",
      "Rule count: 11176, Iteration: 1\n",
      "Target rule count satisfied: 1000\n",
      "len(rules) 1000\n",
      "done ionosphere0 0.916666666667\n",
      "done m2 ionosphere0 0.916666666667\n",
      "Running apriori with setting: confidence=0.5, support=0.0, minlen=2, maxlen=3, MAX_RULE_LEN=35\n",
      "Rule count: 12443, Iteration: 1\n",
      "Target rule count satisfied: 1000\n",
      "len(rules) 1000\n",
      "done ionosphere1 0.916666666667\n",
      "done m2 ionosphere1 0.916666666667\n",
      "Running apriori with setting: confidence=0.5, support=0.0, minlen=2, maxlen=3, MAX_RULE_LEN=35\n",
      "Rule count: 11668, Iteration: 1\n",
      "Target rule count satisfied: 1000\n",
      "len(rules) 1000\n",
      "done ionosphere2 0.972222222222\n",
      "done m2 ionosphere2 0.972222222222\n",
      "Running apriori with setting: confidence=0.5, support=0.0, minlen=2, maxlen=3, MAX_RULE_LEN=35\n",
      "Rule count: 12162, Iteration: 1\n",
      "Target rule count satisfied: 1000\n",
      "len(rules) 1000\n",
      "done ionosphere3 0.972222222222\n",
      "done m2 ionosphere3 0.972222222222\n",
      "Running apriori with setting: confidence=0.5, support=0.0, minlen=2, maxlen=3, MAX_RULE_LEN=35\n",
      "Rule count: 12300, Iteration: 1\n",
      "Target rule count satisfied: 1000\n",
      "len(rules) 1000\n",
      "done ionosphere4 0.916666666667\n",
      "done m2 ionosphere4 0.916666666667\n",
      "Running apriori with setting: confidence=0.5, support=0.0, minlen=2, maxlen=3, MAX_RULE_LEN=35\n",
      "Rule count: 12765, Iteration: 1\n",
      "Target rule count satisfied: 1000\n",
      "len(rules) 1000\n"
     ]
    }
   ],
   "source": [
    "from cba.algorithms import top_rules\n",
    "from cba.data_structures import TransactionDB, Consequent, Antecedent, Item, ClassAssocationRule\n",
    "from cba.algorithms import M1Algorithm, M2Algorithm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "directory = \"c:/code/python/machine_learning/assoc_rules\"\n",
    "\n",
    "def func(datasetname):\n",
    "    pd_ds = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/train/{}.csv\".format(datasetname))\n",
    "    txns = TransactionDB.from_pandasdf(pd_ds)\n",
    "    \n",
    "    txns_test = TransactionDB.from_pandasdf(pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/test/{}.csv\".format(datasetname)))\n",
    "\n",
    "    rules = top_rules(txns.string_representation, appearance=txns.appeardict)\n",
    "\n",
    "    rules.sort(reverse=True)\n",
    "\n",
    "\n",
    "    cars = []\n",
    "    for idx, rule in enumerate(rules):\n",
    "        con_tmp, ant_tmp, support, confidence = rule\n",
    "\n",
    "        con = Consequent(*con_tmp.split(\"=\"))\n",
    "\n",
    "        ant_items = [ Item(*i.split(\"=\")) for i in ant_tmp ]\n",
    "        ant = Antecedent(ant_items)\n",
    "\n",
    "        id_len = len(ant)\n",
    "\n",
    "        car = ClassAssocationRule(ant, con, support=support, confidence=confidence, id_rule=id_len)\n",
    "        cars.append(car)\n",
    "\n",
    "    cars.sort(reverse=True)\n",
    "\n",
    "    if len(cars) > 1000:\n",
    "        cars = cars[:1000]\n",
    "        \n",
    "\n",
    "    print(\"len(rules)\", len(cars))\n",
    "\n",
    "    m1 = M1Algorithm(cars, txns)\n",
    "    \n",
    "    m2 = M2Algorithm(cars, txns)\n",
    "    \n",
    "    m1clf = m1.build()\n",
    "    m2clf = m2.build()\n",
    "    \n",
    "    \n",
    "    actual = list(map(lambda i: i.value, txns_test.class_labels))\n",
    "\n",
    "    pred = m1clf.predict_all(txns_test)\n",
    "    predM2 = m2clf.predict_all(txns_test)\n",
    "    \n",
    "    accM2 = accuracy_score(predM2, actual)\n",
    "    acc = accuracy_score(pred, actual)\n",
    "\n",
    "    return acc, accM2\n",
    "\n",
    "\n",
    "\n",
    "def mean_func(dataset_name):\n",
    "    files = [ dataset_name + repr(i) for i in range(10) ]\n",
    "\n",
    "    accs = []\n",
    "    accsM2 = []\n",
    "    \n",
    "    for file in files:\n",
    "        acc, accM2 = func(file)\n",
    "        print(\"done\", file, acc)\n",
    "        print(\"done m2\", file, accM2)\n",
    "        accs.append(acc)\n",
    "        accsM2.append(accM2)\n",
    "        \n",
    "    mn = sum(accs) / len(accs)\n",
    "    mnM2 = sum(accsM2) / len(accsM2)\n",
    "    \n",
    "    return mn, mnM2\n",
    "\n",
    "\n",
    "                \n",
    "datasets = [\"breast-w\", \"anneal\", \"hypothyroid\", \"ionosphere\", \"lymph\", \"vehicle\", \"autos\", \"diabetes\", \"glass\", \"heart-h\", \"tic-tac-toe\", \"australian\"]    \n",
    "\n",
    "means = []\n",
    "for dataset in [\"ionosphere\"]:\n",
    "    acc, accM2 = mean_func(dataset)\n",
    "    print(\"*****\")\n",
    "    print(\"M1\", dataset, acc)\n",
    "    print(\"M2\", dataset, accM2)\n",
    "    print(\"******\")\n",
    "    \n",
    "    means.append((dataset, acc))\n",
    "    \n",
    "    \n",
    "print(means)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
