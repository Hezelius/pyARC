{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../../main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RuleBuilderAlgorithm:\n",
    "    def __init__(self, rules, dataset):\n",
    "        self.rules = rules\n",
    "        self.dataset = dataset\n",
    "        self.y = dataset.class_labels\n",
    "        \n",
    "    def update_class_distr(self, classdist, rule):\n",
    "        return classdist - rule.class_cases_covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from cba.algorithms import Classifier\n",
    "\n",
    "import time\n",
    "\n",
    "class M1Algorithm(RuleBuilderAlgorithm):\n",
    "    \n",
    "    def build(self):\n",
    "        classifier = []\n",
    "        self.rules.sort(reverse=True)\n",
    "        dataset = set(self.dataset)\n",
    "        dataset_len = len(dataset)\n",
    "        dataset_len_updated = dataset_len\n",
    "        \n",
    "        default_classes = []\n",
    "        default_classes_errors = []\n",
    "        rule_errors = []\n",
    "        total_errors = []    \n",
    "        \n",
    "        for rule in self.rules:\n",
    "            \n",
    "            if (dataset_len_updated <= 0):\n",
    "                break\n",
    "            \n",
    "            temp = set()\n",
    "            temp_len = 0\n",
    "            temp_satisfies_conseq_cnt = 0\n",
    "            \n",
    "            \n",
    "            for datacase in dataset:\n",
    "                if rule.antecedent <= datacase:\n",
    "                    temp.add(datacase)\n",
    "                    temp_len += 1\n",
    "\n",
    "                    if rule.consequent == datacase.class_val:  \n",
    "                        temp_satisfies_conseq_cnt += 1\n",
    "                        rule.marked = True\n",
    "                        \n",
    "\n",
    "            if rule.marked:\n",
    "\n",
    "                classifier.append(rule)\n",
    "                \n",
    "                dataset -= temp\n",
    "                dataset_len_updated -= temp_len\n",
    "                \n",
    "                \n",
    "                ctr = collections.Counter(map(lambda d: d.class_val.value, dataset))\n",
    "                \n",
    "                # this will be the default class\n",
    "                most_common_tuple = ctr.most_common(1)\n",
    "                \n",
    "                most_common_cnt = 0\n",
    "                most_common_label = \"None\"\n",
    "                \n",
    "                try:\n",
    "                    most_common_tuple = most_common_tuple[0]\n",
    "                    most_common_cnt = most_common_tuple[1]\n",
    "                    most_common_label = most_common_tuple[0]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                \n",
    "                    \n",
    "                \n",
    "                # this is the default class label inserted at corresponding list\n",
    "                default_classes.append(most_common_label)\n",
    "                \n",
    "                \n",
    "                # number of errors the rule will make => all_satisfying - conseq_satisfying\n",
    "                rule_errors.append(temp_len - temp_satisfies_conseq_cnt)\n",
    "                \n",
    "                \n",
    "                dflt_class_err = dataset_len_updated - most_common_cnt\n",
    "                err_cnt = dflt_class_err\n",
    "                    \n",
    "                \n",
    "                \n",
    "                default_classes_errors.append(err_cnt)\n",
    "                \n",
    "                total_errors.append(err_cnt + sum(rule_errors))\n",
    "                \n",
    "                \n",
    "                \n",
    "            temp = set()\n",
    "            temp_len = 0\n",
    "            temp_satisfies_conseq_cnt = 0\n",
    "            \n",
    "\n",
    "        min_errors = min(total_errors)\n",
    "        \n",
    "        print(total_errors)\n",
    "        \n",
    "        indices_to_cut = [ i for i in range(len(total_errors)) if total_errors[i] == min_errors ]\n",
    "        \n",
    "        idx_to_cut = indices_to_cut[0]\n",
    "        \n",
    "        classif = classifier[:idx_to_cut+1]\n",
    "        default_class = default_classes[idx_to_cut]        \n",
    "        \n",
    "        clf = Classifier()\n",
    "        clf.rules = classif\n",
    "        clf.default_class = default_class\n",
    "        \n",
    "        return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cba.algorithms import Classifier\n",
    "from cba.data_structures import ClassAssocationRule, Antecedent, Consequent\n",
    "\n",
    "import collections\n",
    "\n",
    "class M2Algorithm(RuleBuilderAlgorithm):\n",
    "    \n",
    "    def build(self):\n",
    "\n",
    "        self.rules.sort(reverse=True)\n",
    "        \n",
    "        self.dataset_frozen = self.dataset\n",
    "        self.dataset_len = len(self.dataset_frozen)\n",
    "\n",
    "        # set of crules that have higher precedence\n",
    "        # that their corresponding wrules\n",
    "        self.Q = set()\n",
    "        \n",
    "        # set of all crules\n",
    "        self.U = set()\n",
    "        \n",
    "        # set of conflicting rules\n",
    "        self.A = set()\n",
    "        \n",
    "        self.classifier = []\n",
    "        \n",
    "        self.stage1()\n",
    "        self.stage2()\n",
    "        self.stage3()\n",
    "        \n",
    "        clf = Classifier()\n",
    "        clf.rules = self.classifier\n",
    "        clf.default_class = self.default_class\n",
    "        \n",
    "        return clf\n",
    "    \n",
    "        \n",
    "    def stage1(self):\n",
    "        \n",
    "        for datacase in self.dataset_frozen:\n",
    "            # finds the highest precedence crules and wrules\n",
    "            crule, wrule = self.maxcoverrule(datacase, self.rules)\n",
    "        \n",
    "            if crule is None:\n",
    "                crule = self.emptyrule()\n",
    "                \n",
    "            if wrule is None:\n",
    "                wrule = self.emptyrule()\n",
    "                \n",
    "            self.U.add(crule)\n",
    "            \n",
    "            crule.class_cases_covered.update([datacase.class_val.value])\n",
    "            \n",
    "            if crule > wrule:\n",
    "                self.Q.add(crule)\n",
    "                crule.marked = True\n",
    "            else:\n",
    "                structure = (datacase, datacase.class_val.value, crule, wrule)\n",
    "                self.A.add(structure)\n",
    "                \n",
    "            \n",
    "                \n",
    "    \n",
    "    def stage2(self):\n",
    "        \n",
    "        for conflicting_struct in self.A:\n",
    "            datacase, clazz, crule, wrule = conflicting_struct\n",
    "            \n",
    "            \n",
    "            if wrule.marked:\n",
    "                crule.class_cases_covered[clazz] -= 1\n",
    "                wrule.class_cases_covered[clazz] += 1\n",
    "            \n",
    "            else:\n",
    "                wset = self.allcover_rules(self.U, datacase, crule)\n",
    "                for w in wset:\n",
    "                    w.replace.add((crule, datacase, clazz))\n",
    "                    w.class_cases_covered[clazz] += 1\n",
    "                    \n",
    "                self.Q = self.Q.union(wset)\n",
    "        \n",
    "        \n",
    "    def stage3(self):\n",
    "        Qlist = sorted(self.Q, reverse=True)\n",
    "\n",
    "        rule_errors = 0\n",
    "        rule_supcount = 0\n",
    "        total_errors_list = []\n",
    "        default_classes_list = []\n",
    "        rules_list = []\n",
    "        \n",
    "        # class distribution\n",
    "        classdist = collections.Counter(map(lambda d: d.class_val.value, self.dataset_frozen))\n",
    "        \n",
    "        for rule in Qlist:\n",
    "            if rule.class_cases_covered[rule.consequent.value] > 0:\n",
    "                for (rule_replace, dcase, clazz) in rule.replace:\n",
    "                    if dcase.alreadycovered == True:\n",
    "                        rule.class_cases_covered[clazz] -= 1\n",
    "                    else:\n",
    "                        dcase.alreadycovered = True\n",
    "                        rule_replace.class_cases_covered[clazz] -= 1\n",
    "                \n",
    "                rule_errors += self.errors_of_rule(rule)\n",
    "                rule_supcount += rule.support_count\n",
    "                \n",
    "                classdist = self.update_class_distr(classdist, rule)\n",
    "                \n",
    "                \n",
    "                default_class = self.select_default_class(classdist)\n",
    "                default_class_count = default_class[1]\n",
    "                default_class_label = default_class[0]\n",
    "                \n",
    "                default_errors = self.dataset_len - rule_supcount - default_class_count\n",
    "                \n",
    "                total_errors = rule_errors + default_errors\n",
    "                \n",
    "                rules_list.append(rule)\n",
    "                default_classes_list.append(default_class_label)\n",
    "                total_errors_list.append(total_errors)\n",
    "                \n",
    "        \n",
    "        min_value = min(total_errors_list)\n",
    "        \n",
    "        min_indices = [ idx for (idx, err_num) in enumerate(total_errors_list) if err_num == min_value ]\n",
    "        min_idx = min_indices[0]\n",
    "        \n",
    "        print(total_errors_list)\n",
    "        \n",
    "        final_classifier = [ rule for rule in rules_list[:min_idx + 1] ]\n",
    "        default_class = default_classes_list[min_idx]\n",
    "\n",
    "        if not default_class:\n",
    "            i = min_idx\n",
    "            while not default_class:\n",
    "                i -= 1\n",
    "                default_class = default_classes_list[i]\n",
    "\n",
    "        self.classifier = final_classifier\n",
    "        self.default_class = default_class\n",
    "        \n",
    "    \n",
    "    def emptyrule(self):\n",
    "        return ClassAssocationRule(Antecedent([]), Consequent(None, None), 0, 0)\n",
    "    \n",
    "    \n",
    "    def maxcoverrule(self, datacase, rules):\n",
    "        \"\"\"\n",
    "        finds the highest precedence rule that covers\n",
    "        the case d\n",
    "        \n",
    "        \n",
    "        arguments:\n",
    "            rules: sorted rules\n",
    "            datacase: instance d\n",
    "            sameclass:\n",
    "                if we are looking for rules\n",
    "                with the same class as datacase\n",
    "            \n",
    "        \"\"\"\n",
    "        crule, wrule = None, None\n",
    "        \n",
    "        \n",
    "        for rule in rules:\n",
    "            if rule.antecedent <= datacase:\n",
    "                if rule.consequent == datacase.class_val and not crule:\n",
    "                    # save cRule\n",
    "                    crule = rule\n",
    "                    if crule and wrule:\n",
    "                        return crule, wrule\n",
    "                elif rule.consequent != datacase.class_val and not wrule:\n",
    "                    # save wRule\n",
    "                    wrule = rule\n",
    "                    if crule and wrule:\n",
    "                        return crule, wrule\n",
    "\n",
    "        \n",
    "        \n",
    "        return crule, wrule\n",
    "    \n",
    "    \n",
    "    def allcover_rules(self, U, datacase, crule):\n",
    "        wset = set()\n",
    "        \n",
    "        for replacingrule in U:\n",
    "            if replacingrule > crule and replacingrule.antecedent <= datacase and replacingrule.consequent.value != datacase.class_val.value:\n",
    "                wset.add(replacingrule)\n",
    "        \n",
    "        return wset\n",
    "    \n",
    "    def errors_of_rule(self, rule):\n",
    "        rule.support_count = sum(rule.class_cases_covered.values()) \n",
    "        return rule.support_count - rule.class_cases_covered[rule.consequent.value]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def select_default_class(self, classdist):\n",
    "        most_common = classdist.most_common(1)\n",
    "        \n",
    "        if not most_common:\n",
    "            return (None, 0)\n",
    "        \n",
    "        return most_common[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cba.data_structures import ComparableItemSet\n",
    "from cba.data_structures import Item\n",
    "\n",
    "\n",
    "class Transaction(ComparableItemSet):\n",
    "\n",
    "    id_ = 0\n",
    "    \n",
    "    def __init__(self, row, header, class_item):\n",
    "        self.class_val = class_item\n",
    "        self.items = []\n",
    "        self.tid = Transaction.id_\n",
    "        Transaction.id_ += 1\n",
    "        \n",
    "        self.alreadycovered = False\n",
    "        self.hidden = False\n",
    "        \n",
    "        # eg. [pay=high, eyes=green]\n",
    "        self.string_items = []\n",
    "        \n",
    "        \n",
    "        for idx, val in enumerate(row):\n",
    "            header_label = header[idx]\n",
    "            \n",
    "            item = Item(header_label, val)\n",
    "            \n",
    "            self.string_items.append(\"{}:=:{}\".format(header_label, val)) \n",
    "            \n",
    "            self.items.append(item)\n",
    "            \n",
    "        key, val = self.class_val\n",
    "        self.string_items.append(\"{}:=:{}\".format(key, val))\n",
    "\n",
    "        self.frozenset = frozenset(self)\n",
    "            \n",
    "            \n",
    "    \n",
    "    def __repr__(self):\n",
    "        string = \", \".join(self.string_items) \n",
    "        return \"{\" + string + \"}\"\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(tuple(self.items))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return hash(self) == hash(other)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.items[idx]\n",
    "    \n",
    "    def getclass(self):\n",
    "        return self.class_val\n",
    "    \n",
    "    \n",
    "    \n",
    "class UniqueTransaction(Transaction):\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cba.data_structures import Appearance, Transaction, Item\n",
    "\n",
    "class TransactionDB:\n",
    "    \n",
    "    def __init__(self, dataset, header, unique_transactions=False):\n",
    "        \"\"\"\n",
    "        arguments:\n",
    "        - dataset: [[primitive]]\n",
    "        - header: [string] - feature labels\n",
    "        \n",
    "        assert:\n",
    "        - len(header) == len(values_list)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        TransactionClass = UniqueTransaction if unique_transactions else Transaction\n",
    "        \n",
    "        self.header = header\n",
    "        self.class_labels = []\n",
    "        \n",
    "        new_dataset = []\n",
    "\n",
    "        for row in dataset:\n",
    "            class_label = Item(header[-1], row[-1])\n",
    "            new_row = TransactionClass(row[:-1], header[:-1], class_label)\n",
    "            \n",
    "            self.class_labels.append(class_label)\n",
    "            \n",
    "            new_dataset.append(new_row)\n",
    "            \n",
    "        self.data = new_dataset\n",
    "        self.classes = list(map(lambda i: i[1], self.class_labels))\n",
    "        \n",
    "        \n",
    "        \n",
    "        get_string_items = lambda transaction: transaction.string_items\n",
    "        \n",
    "        mapped = map(get_string_items, self)\n",
    "        \n",
    "        self.string_representation = list(mapped)\n",
    "        \n",
    "        \n",
    "\n",
    "    @property\n",
    "    def appeardict(self):\n",
    "        appear = Appearance()\n",
    "        \n",
    "        unique_class_items = set(self.class_labels)\n",
    "        \n",
    "        for item in unique_class_items:\n",
    "            appear.add_to_RHS(item)\n",
    "\n",
    "        return appear.dictionary\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def from_DataFrame(clazz, df, unique_transactions=False):\n",
    "        \"\"\"\n",
    "        convert pandas dataframe to DataSet\n",
    "        \"\"\"\n",
    "        \n",
    "        rows = df.values\n",
    "        header = list(df.columns.values)\n",
    "\n",
    "        return clazz(rows, header, unique_transactions=unique_transactions)\n",
    "\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(self.string_representation)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cba.algorithms import Classifier\n",
    "import pandas as pd\n",
    "from cba.algorithms import generateCARs\n",
    "import sklearn.metrics as skmetrics\n",
    "\n",
    "dsname = \"credit-g0\"\n",
    "\n",
    "#iris_train = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/train/{}.csv\".format(dsname))\n",
    "iris_train = pd.read_csv(\"../data/movies_discr.csv\", sep=\";\")\n",
    "iris_train = iris_train.set_index(\"Unnamed: 0\")\n",
    "iris_txns = TransactionDB.from_DataFrame(iris_train, unique_transactions=True)\n",
    "\n",
    "iris_test = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/test/{}.csv\".format(dsname))\n",
    "iris_txns_test = TransactionDB.from_DataFrame(iris_test, unique_transactions=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimated-budget</th>\n",
       "      <th>a-list-celebrities</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;150;200)</td>\n",
       "      <td>&lt;0;2)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;50;100)</td>\n",
       "      <td>&lt;0;2)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;50;100)</td>\n",
       "      <td>&lt;0;2)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;50;100)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;200;250)</td>\n",
       "      <td>&lt;0;2)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;150;200)</td>\n",
       "      <td>&lt;0;2)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;0;50)</td>\n",
       "      <td>&lt;0;2)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;200;250)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;150;200)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;100;150)</td>\n",
       "      <td>&lt;0;2)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;0;50)</td>\n",
       "      <td>&lt;0;2)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;50;100)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;0;50)</td>\n",
       "      <td>&lt;0;2)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;50;100)</td>\n",
       "      <td>&lt;0;2)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;0;50)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;0;50)</td>\n",
       "      <td>&lt;0;2)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;100;150)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>box-office-bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;50;100)</td>\n",
       "      <td>&lt;4;6)</td>\n",
       "      <td>main-stream-hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;50;100)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>main-stream-hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;250;300)</td>\n",
       "      <td>&lt;4;6)</td>\n",
       "      <td>main-stream-hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;250;300)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>main-stream-hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;200;250)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>main-stream-hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;150;200)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>main-stream-hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;150;200)</td>\n",
       "      <td>&lt;4;6)</td>\n",
       "      <td>main-stream-hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;100;150)</td>\n",
       "      <td>&lt;4;6)</td>\n",
       "      <td>main-stream-hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;100;150)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>main-stream-hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;50;100)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>critical-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&lt;0;50)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>critical-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;0;50)</td>\n",
       "      <td>&lt;4;6)</td>\n",
       "      <td>critical-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;50;100)</td>\n",
       "      <td>&lt;4;6)</td>\n",
       "      <td>critical-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>&lt;50;100)</td>\n",
       "      <td>&lt;6;8)</td>\n",
       "      <td>critical-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>&lt;150;200)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>critical-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>&lt;150;200)</td>\n",
       "      <td>&lt;2;4)</td>\n",
       "      <td>critical-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>&lt;50;100)</td>\n",
       "      <td>&lt;4;6)</td>\n",
       "      <td>critical-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>&lt;0;50)</td>\n",
       "      <td>&lt;4;6)</td>\n",
       "      <td>critical-success</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           estimated-budget a-list-celebrities             class\n",
       "Unnamed: 0                                                      \n",
       "0                 <150;200)              <0;2)   box-office-bomb\n",
       "1                  <50;100)              <0;2)   box-office-bomb\n",
       "2                  <50;100)              <0;2)   box-office-bomb\n",
       "3                  <50;100)              <2;4)   box-office-bomb\n",
       "4                 <200;250)              <0;2)   box-office-bomb\n",
       "5                 <150;200)              <0;2)   box-office-bomb\n",
       "6                    <0;50)              <0;2)   box-office-bomb\n",
       "7                 <200;250)              <2;4)   box-office-bomb\n",
       "8                 <150;200)              <2;4)   box-office-bomb\n",
       "9                 <100;150)              <0;2)   box-office-bomb\n",
       "10                   <0;50)              <0;2)   box-office-bomb\n",
       "11                 <50;100)              <2;4)   box-office-bomb\n",
       "12                   <0;50)              <0;2)   box-office-bomb\n",
       "13                 <50;100)              <0;2)   box-office-bomb\n",
       "14                   <0;50)              <2;4)   box-office-bomb\n",
       "15                   <0;50)              <0;2)   box-office-bomb\n",
       "16                <100;150)              <2;4)   box-office-bomb\n",
       "17                 <50;100)              <4;6)   main-stream-hit\n",
       "18                 <50;100)              <2;4)   main-stream-hit\n",
       "19                <250;300)              <4;6)   main-stream-hit\n",
       "20                <250;300)              <2;4)   main-stream-hit\n",
       "21                <200;250)              <2;4)   main-stream-hit\n",
       "22                <150;200)              <2;4)   main-stream-hit\n",
       "23                <150;200)              <4;6)   main-stream-hit\n",
       "24                <100;150)              <4;6)   main-stream-hit\n",
       "25                <100;150)              <2;4)   main-stream-hit\n",
       "26                 <50;100)              <2;4)  critical-success\n",
       "27                   <0;50)              <2;4)  critical-success\n",
       "28                   <0;50)              <4;6)  critical-success\n",
       "29                 <50;100)              <4;6)  critical-success\n",
       "30                 <50;100)              <6;8)  critical-success\n",
       "31                <150;200)              <2;4)  critical-success\n",
       "32                <150;200)              <2;4)  critical-success\n",
       "33                 <50;100)              <4;6)  critical-success\n",
       "34                   <0;50)              <4;6)  critical-success"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cba.algorithms import top_rules, createCARs\n",
    "import fim\n",
    "\n",
    "def generateCARs(transactionDB, support=1, confidence=50, maxlen=10, **kwargs):\n",
    "    appear = transactionDB.appeardict\n",
    "    \n",
    "    rules = fim.apriori(transactionDB.string_representation, supp=support, conf=confidence, target=\"r\", report=\"sc\", appear=appear, **kwargs, zmax=maxlen)\n",
    "    \n",
    "    print(\"done\")\n",
    "    \n",
    "    return createCARs(rules)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "[15, 13, 13, 12, 12, 11, 10, 9, 9, 9, 8, 8]\n",
      "[15, 13, 13, 12, 12, 11, 10, 9, 9, 9, 8, 8]\n",
      "                                                  lhs                     rhs  \\\n",
      "0                          {a-list-celebrities=<0;2)}   class=box-office-bomb   \n",
      "1                        {estimated-budget=<250;300)}   class=main-stream-hit   \n",
      "2   {a-list-celebrities=<4;6),estimated-budget=<0;...  class=critical-success   \n",
      "3                          {a-list-celebrities=<6;8)}  class=critical-success   \n",
      "4   {estimated-budget=<100;150),a-list-celebrities...   class=main-stream-hit   \n",
      "5   {a-list-celebrities=<4;6),estimated-budget=<15...   class=main-stream-hit   \n",
      "6                        {estimated-budget=<200;250)}   class=box-office-bomb   \n",
      "7   {a-list-celebrities=<4;6),estimated-budget=<50...  class=critical-success   \n",
      "8                           {estimated-budget=<0;50)}   class=box-office-bomb   \n",
      "9                        {estimated-budget=<100;150)}   class=main-stream-hit   \n",
      "10  {a-list-celebrities=<2;4),estimated-budget=<15...  class=critical-success   \n",
      "\n",
      "    confidence   support  length     id  \n",
      "0     1.000000  0.314286       2  56918  \n",
      "1     1.000000  0.057143       2  56895  \n",
      "2     1.000000  0.057143       3  56909  \n",
      "3     1.000000  0.028571       2  56892  \n",
      "4     1.000000  0.028571       3  56900  \n",
      "5     1.000000  0.028571       3  56906  \n",
      "6     0.666667  0.057143       2  56899  \n",
      "7     0.666667  0.057143       3  56914  \n",
      "8     0.625000  0.142857       2  56913  \n",
      "9     0.500000  0.057143       2  56902  \n",
      "10    0.500000  0.057143       3  56907  \n",
      "                                                  lhs                     rhs  \\\n",
      "0                          {a-list-celebrities=<0;2)}   class=box-office-bomb   \n",
      "1                        {estimated-budget=<250;300)}   class=main-stream-hit   \n",
      "2   {a-list-celebrities=<4;6),estimated-budget=<0;...  class=critical-success   \n",
      "3                          {a-list-celebrities=<6;8)}  class=critical-success   \n",
      "4   {estimated-budget=<100;150),a-list-celebrities...   class=main-stream-hit   \n",
      "5   {a-list-celebrities=<4;6),estimated-budget=<15...   class=main-stream-hit   \n",
      "6                        {estimated-budget=<200;250)}   class=box-office-bomb   \n",
      "7   {a-list-celebrities=<4;6),estimated-budget=<50...  class=critical-success   \n",
      "8                           {estimated-budget=<0;50)}   class=box-office-bomb   \n",
      "9                        {estimated-budget=<100;150)}   class=main-stream-hit   \n",
      "10  {a-list-celebrities=<2;4),estimated-budget=<15...  class=critical-success   \n",
      "\n",
      "    confidence   support  length     id  \n",
      "0     1.000000  0.314286       2  56918  \n",
      "1     1.000000  0.057143       2  56895  \n",
      "2     1.000000  0.057143       3  56909  \n",
      "3     1.000000  0.028571       2  56892  \n",
      "4     1.000000  0.028571       3  56900  \n",
      "5     1.000000  0.028571       3  56906  \n",
      "6     0.666667  0.057143       2  56899  \n",
      "7     0.666667  0.057143       3  56914  \n",
      "8     0.625000  0.142857       2  56913  \n",
      "9     0.500000  0.057143       2  56902  \n",
      "10    0.500000  0.057143       3  56907  \n"
     ]
    }
   ],
   "source": [
    "cars = generateCARs(iris_txns, support=-1, maxlen=4)\n",
    "\n",
    "m1clf = M1Algorithm(cars, iris_txns).build()\n",
    "m2clf = M2Algorithm(cars, iris_txns).build()\n",
    "\n",
    "print(m1clf.inspect())\n",
    "\n",
    "print(m2clf.inspect())\n",
    "\n",
    "#print(m1clf.test_transactions(iris_txns_test))\n",
    "#print(m2clf.test_transactions(iris_txns_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1clf.rules == m2clf.rules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
